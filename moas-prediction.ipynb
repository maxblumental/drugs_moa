{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.utils.data as data_utils\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/lish-moa/train_features.csv')\ntarget_df = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest_df = pd.read_csv('../input/lish-moa/test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_array(df):\n    cp_type_encoding = {'trt_cp': 1.0, 'ctl_vehicle': -1.0}\n    cp_time_encoding = {24: -1.0, 48: 0.0, 72: 1.0}\n    cp_dose_encoding = {'D1': -1.0, 'D2': 1.0}\n\n    df['cp_type_enc'] = [cp_type_encoding[x] for x in df.cp_type]\n    df['cp_time_enc'] = [cp_time_encoding[x] for x in df.cp_time]\n    df['cp_dose_enc'] = [cp_dose_encoding[x] for x in df.cp_dose]\n\n    cols = ['cp_type_enc', 'cp_time_enc', 'cp_dose_enc']\n    cols += [c for c in df.columns if c.startswith('g-') or c.startswith('c-')]\n    return df[cols].values\n\ndef target_array(df):\n    return target_df[target_df.columns[1:]].values\n\ndef train_val_split(train_df, target_df, val_size=0.1):\n    assert 0.0 <= val_size <= 1.0, 'val_size must lie within (0; 1)'\n    X = feature_array(train_df)\n    y = target_array(target_df)\n    assert len(X) == len(y)\n    val_count = int(len(X) * val_size)\n    val_indices = np.random.choice(len(X), size=val_count, replace=False)\n    X_val, y_val = X[val_indices], y[val_indices]\n    X_train, y_train = np.delete(X, val_indices, axis=0), np.delete(y, val_indices, axis=0)\n    return X_train, y_train, X_val, y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train, X_val, y_val = train_val_split(train_df, target_df)\n\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = data_utils.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\nval_dataset = data_utils.TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n\ntrain_loader = data_utils.DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = data_utils.DataLoader(val_dataset, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoaModel(torch.nn.Module):\n    def __init__(self, features_num, targets_num):\n        super(MoaModel, self).__init__()\n        self.model = torch.nn.Sequential(\n            torch.nn.Linear(features_num, 512),\n            torch.nn.Dropout(p=0.4),\n            torch.nn.ReLU(),\n            torch.nn.Linear(512, 256),\n            torch.nn.Dropout(p=0.4),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256, targets_num),\n        )\n\n    def forward(self, x):\n        logits = self.model(x)\n        return logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\n\nfrom ignite.contrib.handlers import ProgressBar\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss, RunningAverage\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = MoaModel(\n    features_num=X_train.shape[1], \n    targets_num=y_train.shape[1],\n)\n\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.3)\n\ntrainer = create_supervised_trainer(model, optimizer, F.binary_cross_entropy_with_logits, device=device)\nevaluator = create_supervised_evaluator(\n    model, metrics={\"bce\": Loss(F.binary_cross_entropy_with_logits)}, device=device\n)\n\nRunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n\npbar = ProgressBar(persist=True)\npbar.attach(trainer, metric_names=\"all\")\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(engine):\n    evaluator.run(train_loader)\n    metrics = evaluator.state.metrics\n    avg_bce = metrics[\"bce\"]\n    pbar.log_message(\n        \"Training Results - Epoch: {}  Avg loss: {:.5f}\".format(engine.state.epoch, avg_bce)\n    )\n    \n@trainer.on(Events.EPOCH_COMPLETED)\ndef decrease_lr(engine):\n    scheduler.step()\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_validation_results(engine):\n    evaluator.run(val_loader)\n    metrics = evaluator.state.metrics\n    avg_bce = metrics[\"bce\"]\n    pbar.log_message(\n        \"Validation Results - Epoch: {}  Avg loss: {:.5f}\".format(engine.state.epoch, avg_bce)\n    )\n    pbar.n = pbar.last_print_n = 0\n\ntrainer.run(train_loader, max_epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = torch.FloatTensor(feature_array(test_df)).to(device)\n\nwith torch.no_grad():\n    y_pred = torch.sigmoid(model(X_test)).cpu().numpy()\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')\n\nss[ss.columns[1:]] = y_pred\n\nss.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}